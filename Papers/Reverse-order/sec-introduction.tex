\section{Introduction}

The \commonlisp{} \emph{sequence} functions are defined to work on
lists as well as vectors.  Furthermore, many of these sequence
functions accept a keyword argument \texttt{from-end} that alters the
behavior in that elements toward the end of the sequence are favored
over elements toward the beginning of the sequence.  Other functions,
in particular \texttt{reduce}, also accept this keyword argument.

Most sequence functions are not required to process the elements from
the end of the sequence even though the value of the \texttt{from-end}
keyword argument is \emph{true}.  For example, it is allowed for
\texttt{find} to compare elements from the beginning of the sequence
and return the \emph{last} element that \emph{satisfies the test}%
\footnote{The phrase \emph{satisfy the test} has a precise meaning in
  the \commonlisp{} standard as shown in section 17.2 in that
  document.}
even if the test has side effects.  There is one exception this
requirement, however:  The \texttt{count} function is required by the
standard to test the elements from the end of the sequence.%
\footnote{Though if the test has no side effects and cannot fail, as
  is the case of functions such as \texttt{eq} or \texttt{eql},
  testing from the beginning is arguably conforming behavior.}
In addition to the function \texttt{count}, the function
\texttt{reduce} also requires processing from the end of the list when
\texttt{from-end} is \emph{true}.

Processing list elements from the beginning to the end could, however,
have a significant additional cost associated with it when processing
from the end would require fewer executions of the test function, and
the additional cost increases with the complexity of the test.

The premise of this paper is that the programmer who supplies a true
value to the keyword argument \texttt{:from-end} has an inkling that
it would be more efficient to process the elements from the end, even
when the standard explicitly allows the implementation to violate that
processing order.  At the very least, a programmer that supplies a
true value would have to take into account that at least \emph{some}
implementation may \emph{actually} process the elements from the end.
Therefore, it is likely that the programmer who definitely does not
want elements to be processed form the end, either does not supply a
true value, or would write a special-case version of the sequence
function in question.

For the remainder of this paper, we therefore assume that when a true
value was supplied to the keyword argument \texttt{:from-end}, then
the elements should be processed from the end, unless the following
criteria simultaneously hold:

\begin{itemize}
\item The test is side-effect free
\item The test can not fail (which excludes functions such as numeric
  comparison).
\item Processing from the beginning is guaranteed to be less costly in
  terms of performance.
\end{itemize}

There are of course some very simple methods for processing elements
from the end of a list.

One such method would be to start by reversing the list%
\footnote{By \emph{reversing the list} we do not mean modifying the
  list as \texttt{nreverse} would do, but creating a new list with the
  elements in reverse order as \texttt{reverse} would do.  The reason
  for excluding modifications to the list is that doing so might
  influence the semantics of other functions, including perhaps the
  test function or the view of the list by other threads.}
and processing the elements from the beginning in the reversed list.
We consider such a solution unacceptable, because of the $O(n)$
additional space required, and the additional execution time required
by the memory allocator and the garbage collector.

Another simple method would be to traverse the list \emph{recursively}
and testing the elements during the \emph{backtracking} phase of the
recursion.  Again, $O(n)$ extra space is required, even though this
time the memory allocator and the garbage collector are not solicited,
at least in most implementations.  Worse, many implementations have a
fairly small call stack, especially in multi-threaded implementations
where each thread must have a dedicated stack.  Aside from these
disadvantages, this method is however fairly efficient in terms of
execution time, because a simple function call is quite fast on most
modern processors.  For that reason, we will use recursion as the
basis of the technique described in this paper, but with fairly few
recursive calls so that the additional extra space is modest.

Throughout this paper, we assume that the lists to be processed have a
large number of elements, for several reasons:

\begin{itemize}
\item We do not want the list to be small enough to fit in the cache,
  because cache performance depends on other workload as well.
\item For short lists, performance may be dominated by the overhead of
  calling a few functions, or by loop prologues and epilogues.  By
  using long lists, we make sure that performance is dominated by
  traversing the list and computing the test.
\item We need for the list to have orders of magnitude more elements
  than can be processed by a simple recursive technique.
\end{itemize}

In this paper, we use the international convention for writing
logarithms.  Hence, we write $\mathsf{lb}\thinspace n$ for the
logarithm in base~$2$.  We use $\mathsf{log}$ only when the base is
unimportant.

%%  LocalWords:  startup runtime allocator
