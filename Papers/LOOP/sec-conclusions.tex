\section{Conclusions and future work}

We have described a modern implementation of the \commonlisp{}
\texttt{loop} macro.  The main benefit of our method is better
\emph{modularity} compared to existing implementations, which makes
maintenance easier, and also allows for more modular integration of
client-defined extensions.

Our implementation contains significantly more code than, for
instance, MIT LOOP; more than $5000$ lines compared to $2000$.  There
are several explanations for this discrepancy:

\begin{itemize}
\item Our code has more lines of comments; nearly $1500$ compared to
  less than $200$ for MIT LOOP.
\item Our implementation is divided into nearly $50$ files, or
  \emph{modules}, and each new file represents some overhead in terms
  of code size,
\item Our implementation contains more semantic verification as shown
  by the fact that it rejects the examples of non-conforming code shown
  in \refSec{sec-mit-loop}.
\item Commonalities between clause types are captured as explicit
  class definitions which require additional code.
\item We most likely have not identified all the instances where
  refactoring the code would be beneficial.
\end{itemize}

\subsection{Use external parser framework}

When we started the work on this library, we were unaware of any
existing libraries for combinator parsing written in \commonlisp{}.
Since then, we have been made aware of the library named
``cl-parser-combinators''%
\footnote{https://github.com/Ramarren/cl-parser-combinators} which is
a library for combinator parsing inspired by Parsec
\cite{Leijen:Meijer:Parsec}.  Parsec was originally written in
Haskell, and later re-implemented in other languages as well.

We plan to evaluate cl-parser-combinators to determine whether it
provides the functionality required for parsing \texttt{loop} clauses,
and if not, whether it can be extended to provide such functionality.

A significant advantage of using cl-parser-combinators over the
existing technique is that cl-parser-combinators has full support for
the most general backtracking capabilities of combinator parsing.
Using it rather than our current technique would make it unnecessary
to consider careful ordering of clause parsers the way we currently
need to do.

A possible disadvantage might be that full backtracking is potentially
costly in terms of performance.  However, we do not expect performance
of clause parsers to be a determining factor for the overall
performance of a \commonlisp{} compiler.

\subsection{Second clause parser}

As mentioned in \refSec{sec-our-technique}, we are able to signal
appropriate conditions in some cases when the initial attempt is made
to parse the body of the \texttt{loop} form as individual clauses.
However, when a syntax error is detected in some clause, all further
analysis is abandoned.  It would clearly be better if the analysis
could continue with the remaining clauses, and if an appropriate error
condition could be signaled for the faulty clause.

A simple way of improving error reporting would be to add more parsers
for each clause type.  This additional parsers would recognize
incorrect clause syntax and ultimately result in an error being
signaled, but more importantly, they would succeed so that parsing
could continue with subsequent clauses.

Unfortunately, however, while the parsing technique we use has many
advantages as described in refSec{sec-benefits}, it also has the main
disadvantage that parsing gets slower as more parsers need to be
tried, in particular if no care is taken to order the parsers with
respect to probability of success.

We plan to avoid this conundrum by implementing a \emph{second parser}
for parsing individual clauses.  This second parser would be invoked
only when the first one fails.  In that situation, we estimate that
performance is of secondary importance and that emphasis should be on
appropriate error signaling.

\subsection{Code refactoring}

As suggested in the beginning of this section, there are very likely
several remaining opportunities for code refactoring.  Part of the
plan for future work is to identify such opportunities and restructure
the code accordingly, while respecting the existing modular structure
of the code.
